{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b76ea8fa-f165-4dd9-90ca-b4ae645eaf80",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Multi-Modal Sentiment Analysis\n",
    "# Authors and Team\n",
    "### GSBS\n",
    "### Jiawei Song\n",
    "### Ying Xiao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1d6ec6-de41-4983-ae1d-80f04586db30",
   "metadata": {},
   "source": [
    "# 1.- Executive Summary-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6c634d-63c9-4169-a5b4-3b79aa366cea",
   "metadata": {},
   "source": [
    "## Decisions to be impact\n",
    "### This project aims to enhance decision-making processes related to customer feedback analysis. By accurately interpreting and classifying the motivations behind customer comments, organizations can make informed decisions regarding product design, marketing strategies, and customer retention initiatives.\n",
    "## Business value\n",
    "### The insights gained from comprehensive sentiment analysis can significantly boost product-market fit, increase brand demand, and create a sustainable competitive advantage. Accurate sentiment insights can empower businesses to respond effectively to customer needs, ultimately leading to improved customer satisfaction and loyalty.\n",
    "## Data assets\n",
    "### The primary data asset for this project is the CMU-MOSEI dataset, a benchmark dataset designed for multimodal sentiment analysis. CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI) dataset is the largest dataset of multimodal sentiment analysis and emotion recognition to date. The dataset contains more than 22,800 sentence utterance videos from more than 1000 online YouTube speakers. The dataset is gender balanced. All the sentence utterances are randomly chosen from various topics and monologue videos. The videos are transcribed and properly punctuated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31130515-3d1e-490c-91f6-dc12fe9c897b",
   "metadata": {},
   "source": [
    "# 2.- Data Preprocessing-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c21189-4f0c-4304-96d3-4ded493056cc",
   "metadata": {},
   "source": [
    "## Data Description -- summary of datasets and visualizations of input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f2f516-729f-4dcb-9823-33466f873a36",
   "metadata": {},
   "source": [
    "### The dataset consists of 22,856 entries with the following key features:\n",
    "### video_id: Unique identifier for each video.\n",
    "### clip_id: Identifier for each comment clip.\n",
    "### text: The actual comment text.\n",
    "### label: Sentiment score ranging from -3 (highly negative) to 3 (highly positive).\n",
    "### annotation: Categorical representation of sentiment.\n",
    "### Visualizations reveal that the data distribution is roughly centered around neutral sentiment, with outliers present on the negative side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf81a9-aaae-40d5-9676-fcb038ce1bd7",
   "metadata": {},
   "source": [
    "## Introduce the data cleaning metrics you used in the process and outlier detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713d647f-3de4-4e56-9091-bc985153eea8",
   "metadata": {},
   "source": [
    "### Data Integrity Checks: Ensured no missing values in critical fields like text and label, and dropped unnecessary columns like label_T, label_A and label_V to streamline the dataset for analysis.\n",
    "### Outlier Detection: Utilized the Interquartile Range (IQR) method to identify and filter out extreme values in the sentiment scores. This ensured a more robust analysis by focusing on the central tendency of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d894a6-d26a-4d1d-8b38-af2a90d61302",
   "metadata": {},
   "source": [
    "# 3.- Model Updates-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ba3357-13ba-43bc-9e05-d44d8d373e8a",
   "metadata": {},
   "source": [
    "## Include what models you are using or planning to use to support your decision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf85481-c28c-4831-9a5e-9a975364bb00",
   "metadata": {},
   "source": [
    "### 1. VADER (Valence Aware Dictionary and sEntiment Reasoner)\n",
    "#### Type: Lexicon-based model (rule-based)\n",
    "#### Purpose: It analyzes the sentiment polarity of sentences using a predefined lexicon of words and phrases.\n",
    "#### It assigns positive, negative, and neutral sentiment scores to words.\n",
    "#### It considers context modifiers (e.g., \"not bad\" is positive despite \"bad\" being negative).\n",
    "#### Outputs a compound score between -1 (very negative) and +1 (very positive).\n",
    "### 2. SentiWordNet (SWN)\n",
    "#### Type: Lexicon-based model (based on WordNet)\n",
    "#### Purpose: It assigns sentiment polarity scores to words based on their dictionary meanings.\n",
    "#### It looks up words in WordNet, a large database of English words.\n",
    "#### Each word has positive and negative scores.\n",
    "#### Take the average sentiment score for all words in a sentence.\n",
    "#### Outputs a final score (positive - negative) and scales it to [-3,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42ae84e-f690-4de9-8595-0c2c362dd1c5",
   "metadata": {},
   "source": [
    "## A writeup of machine learning workflow as Machine Learning Morphism (MLM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd30fb3-df4c-44bb-b8d5-62be4844e2c3",
   "metadata": {},
   "source": [
    "### The machine learning workflow involves several key steps:\n",
    "### 1. Data Understanding: Gathering data and understanding its structure.\n",
    "### 2. Data Preprocessing: Cleaning and visualizing data for analysis.\n",
    "### 3. Outlier Detection: Drop the outlier (extreme sentiment)\n",
    "### 4. Sentiment Words Extraction: Using VADER and SentiWordNet to extract sentiment words.\n",
    "### 5. Model Training: Training models on the prepared dataset.\n",
    "### 6. Model Evaluation: Assessing model performance using accuracy, precision, recall, F1-score, and confusion matrix.\n",
    "### 7. Model Refinement: Iteratively improving models based on performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf89587-da91-4728-89d1-97cdaab690d0",
   "metadata": {},
   "source": [
    "# 4.- Source Code-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b0db3f-6e34-4de6-82fc-3c64c18cb066",
   "metadata": {},
   "source": [
    "### https://github.com/GioSongjw/Project---sentiment-analysis-.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d404a38-717e-4895-bba5-b2010022bb76",
   "metadata": {},
   "source": [
    "# 5.- Next Steps-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3518afcf-4dd2-4321-a26c-534b3c871417",
   "metadata": {},
   "source": [
    "### 1. Investigates optimal selection and fusion of feature encoders across multiple modalitiesâ€”specifically text, audio and visual data\r\n",
    "### 2. Compare different fusion methods and examine the impact of multi-loss training within the multimodal fusion network\r\n",
    "#### For example,Use pretrained BERT for text, ResNet for video, and wav2vec for audio to enhance feature extraction.\r\n",
    "### 3. Apply attention layers to weigh the importance of different modalities dynamically.\r\n",
    "### 4. Analyze results; refine models based on performance metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
